
# ğŸš— Smart Car Price Prediction using Machine Learning

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)

### ğŸ¯ **Predicting Car Prices with 84% Accuracy!** ğŸ¯

*A comprehensive machine learning project comparing basic vs. advanced preprocessing techniques for car price prediction*

[![GitHub](https://img.shields.io/badge/View_on-GitHub-black?style=flat-square&logo=github)](https://github.com/giri-harsh/car-price-prediction)
[![LinkedIn](https://img.shields.io/badge/Connect-LinkedIn-blue?style=flat-square&logo=linkedin)](https://linkedin.com/in/giri-harsh)

</div>

---

## ğŸŒŸ Project Overview

As a BTech student passionate about data science, I developed this car price prediction system during my internship to explore how different preprocessing techniques impact model performance. The project features **two distinct approaches** - a basic numerical model and an enhanced version with categorical encoding.

**What makes this project special?**
- ğŸ“ˆ Improved accuracy from **82% to 84%** through better preprocessing
- ğŸ”„ Comparative analysis of basic vs. advanced feature engineering
- ğŸ“ Real-world application of machine learning concepts learned in academics
- ğŸ’¡ Demonstrates the power of proper data preprocessing

---

## ğŸ¯ Problem Statement

**Challenge**: Can we accurately predict a car's market price based on its features like brand, model year, fuel type, and mileage?

**Why it matters**: 
- Helps buyers make informed purchasing decisions ğŸ’°
- Assists dealers in competitive pricing strategies ğŸ“Š
- Provides market insights for automotive industry analysis ğŸ¢

---

## ğŸ“Š Dataset Overview

**Source**: [Car Price Prediction Dataset on Kaggle](https://www.kaggle.com/datasets/vijayaadithyanvg/car-price-predictionused-cars)

<details>
<summary>ğŸ“‹ Dataset Features (Click to expand)</summary>

| Feature | Type | Description |
|---------|------|-------------|
| **Name** | Categorical | Car brand and model |
| **Year** | Numerical | Manufacturing year |
| **Selling_Price** | Numerical | Target variable (price) |
| **Present_Price** | Numerical | Current ex-showroom price |
| **Fuel_Type** | Categorical | Petrol/Diesel/CNG |
| **Seller_Type** | Categorical | Dealer/Individual |
| **Transmission** | Categorical | Manual/Automatic |
| **Owner** | Categorical | Number of previous owners |

**Dataset Stats:**
- ğŸ“Š **Samples**: ~300 used cars
- ğŸ·ï¸ **Features**: 8 input features
- ğŸ¯ **Target**: Car selling price
- ğŸ“ˆ **Price Range**: â‚¹0.1L to â‚¹35L+

</details>

---

## ğŸ› ï¸ Technologies & Libraries

<div align="center">

| Technology | Purpose | Version |
|------------|---------|---------|
| **Python** | Core programming language | 3.x |
| **Pandas** | Data manipulation & analysis | Latest |
| **Scikit-learn** | Machine learning algorithms | Latest |
| **LinearRegression** | Regression algorithm | - |
| **OneHotEncoder** | Categorical encoding | - |
| **train_test_split** | Data splitting | - |

</div>

---

## ğŸ—ï¸ Model Architecture

### ğŸ“ˆ **Model 1: Basic Approach** (`car_price_prediction.py`)
```python
ğŸ”¹ Features Used: Numerical features only
ğŸ”¹ Algorithm: Linear Regression
ğŸ”¹ Preprocessing: Minimal (basic cleaning)
ğŸ”¹ Accuracy Achieved: 82% (RÂ² Score)
```

### ğŸš€ **Model 2: Enhanced Approach** (`Car_Price_Prediction_PreProcessed.py`)
```python
ğŸ”¹ Features Used: Numerical + Categorical (encoded)
ğŸ”¹ Algorithm: Linear Regression
ğŸ”¹ Preprocessing: OneHotEncoder for categorical variables
ğŸ”¹ Accuracy Achieved: 84% (RÂ² Score)
ğŸ”¹ Improvement: +2% accuracy boost!
```

<details>
<summary>ğŸ§  Why the Enhanced Model Performs Better</summary>

The enhanced model outperforms the basic version because:

1. **Captures Categorical Information**: Brand names, fuel types, and transmission types significantly impact car prices
2. **OneHot Encoding**: Converts categorical data into numerical format without imposing ordinal relationships
3. **Richer Feature Space**: More features = better pattern recognition
4. **Reduces Information Loss**: Preserves all original data characteristics

</details>

---

## ğŸ“Š Model Performance

### ğŸ† **Performance Comparison**

<div align="center">

| Model | RÂ² Score | MSE | Key Features |
|-------|----------|-----|--------------|
| **Basic Model** | **82%** | Lower | Numerical only |
| **Enhanced Model** | **84%** â­ | Higher | Numerical + Categorical |

</div>

### ğŸ“ˆ **Detailed Metrics**

<details>
<summary>ğŸ“Š Performance Breakdown</summary>

**Basic Model Results:**
```
RÂ² Score: 0.82 (82% variance explained)
MSE: [Calculated during training]
Features: Year, Present_Price, Driven_kms
```

**Enhanced Model Results:**
```
RÂ² Score: 0.84 (84% variance explained) â¬†ï¸
MSE: [Calculated during training]
Features: All original features (encoded)
Improvement: +2% accuracy through better preprocessing!
```

**Key Takeaway**: Even a 2% improvement is significant in real-world applications! ğŸ¯

</details>

---

## ğŸš€ How to Run This Project

### ğŸ“‹ Prerequisites
```bash
pip install pandas scikit-learn numpy matplotlib seaborn
```

### ğŸ”§ Installation & Usage

1. **Clone the Repository**
   ```bash
   git clone https://github.com/giri-harsh/car-price-prediction.git
   cd car-price-prediction
   ```

2. **Run Basic Model**
   ```bash
   python car_price_prediction.py
   ```

3. **Run Enhanced Model**
   ```bash
   python Car_Price_Prediction_PreProcessed.py
   ```

4. **View Results** ğŸ“Š
   Both scripts will output:
   - Model accuracy (RÂ² score)
   - Mean Squared Error
   - Sample predictions

---

## ğŸ“‚ Project Structure

```
car-price-prediction/
â”‚
â”œâ”€â”€ ğŸ“„ car_price_prediction.py           # Basic model (82% accuracy)
â”œâ”€â”€ ğŸš€ Car_Price_Prediction_PreProcessed.py  # Enhanced model (84% accuracy)
â”œâ”€â”€ ğŸ“Š dataset.csv                       # Car price dataset
â”œâ”€â”€ ğŸ“ README.md                         # Project documentation
â”œâ”€â”€ ğŸ“‹ requirements.txt                  # Python dependencies
â”œâ”€â”€ ğŸ“¸ results/                          # Output visualizations
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ prediction_analysis.png
â””â”€â”€ ğŸ““ notebooks/                        # Jupyter notebooks (if any)
    â””â”€â”€ exploratory_analysis.ipynb
```

---

## ğŸ“ Learning Journey & Insights

<details>
<summary>ğŸ’¡ What I Learned from This Project</summary>

**Technical Skills Developed:**
- ğŸ” **Data Preprocessing**: Importance of handling categorical variables properly
- ğŸ“Š **Feature Engineering**: How encoding techniques impact model performance
- ğŸ¯ **Model Evaluation**: Using RÂ² score and MSE for regression tasks
- ğŸ”„ **Comparative Analysis**: Testing different approaches systematically

**Key Insights:**
- âœ¨ **Preprocessing Matters**: Even simple techniques like OneHot encoding can boost accuracy
- ğŸ“ˆ **Domain Knowledge**: Understanding car features helps in better feature selection
- ğŸ¯ **Incremental Improvement**: Small improvements (2%) can have big real-world impact
- ğŸ§  **Learning by Doing**: Hands-on projects solidify theoretical concepts

**Challenges Overcome:**
- ğŸ”§ Handling mixed data types (numerical + categorical)
- ğŸ“Š Choosing appropriate evaluation metrics for regression
- ğŸ¨ Making code readable and well-documented

</details>

---

## ğŸ”® Future Enhancements

- [ ] ğŸ” **Advanced Algorithms**: Try Random Forest, XGBoost, or Neural Networks
- [ ] ğŸ“Š **Feature Engineering**: Create new features like car age, price depreciation rate
- [ ] ğŸ¨ **Visualization Dashboard**: Interactive plots using Plotly/Streamlit
- [ ] ğŸŒ **Web Application**: Deploy model using Flask/FastAPI
- [ ] ğŸ“± **Mobile App**: Create a user-friendly mobile interface
- [ ] ğŸ”„ **Cross-Validation**: Implement k-fold cross-validation for robust evaluation

---

## ğŸ¤ Connect With Me

<div align="center">

**Harsh Giri** | BTech Student & Aspiring Data Scientist ğŸ“

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/giri-harsh)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/giri-harsh)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:2006.harshgiri@gmail.com)

*Let's connect and discuss machine learning, data science, or any exciting tech projects!*

</div>

---

## ğŸ“š Dataset Credit

ğŸ”— **Dataset Source**: [Car Price Prediction - Used Cars](https://www.kaggle.com/datasets/vijayaadithyanvg/car-price-predictionused-cars)

*Special thanks to the Kaggle community for providing this comprehensive dataset!*



<div align="center">

### ğŸŒŸ Found this project helpful? Give it a â­!

**Made with ğŸ’» & â˜• by Harsh Giri during my internship journey**

*"Every line of code is a step closer to becoming a better data scientist!" ğŸš€*

---

**Contributions, suggestions, and feedback are always welcome! ğŸ¤**

</div>

---

<sub>ğŸš— *"This project taught me that in machine learning, the devil is in the details - and those details make all the difference!"* - Harsh</sub>
